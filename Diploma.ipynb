{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyWAENFdkjDH"
      },
      "outputs": [],
      "source": [
        "from scipy.io import loadmat\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from matplotlib.pyplot import imshow\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, datasets, models\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "import copy\n",
        "import torch, gc\n",
        "import skimage\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms.functional as TF\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import tqdm\n",
        "from tqdm import tqdm_notebook\n",
        "import scipy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvnJ6_fPklKW"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7HnJLLi1zwI"
      },
      "outputs": [],
      "source": [
        "!ls drive/MyDrive/University/Science"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPwqIHLpkoRq"
      },
      "outputs": [],
      "source": [
        "%cd drive/MyDrive/University/Science/code/NucleiSegmentationAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "fGOB1Znvb-Kj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bo0DDRQmkrJH"
      },
      "outputs": [],
      "source": [
        "############################################\n",
        "# Display Image and its corresponding Mask #\n",
        "############################################\n",
        "x = loadmat('./Train/Labels/train_1.mat')\n",
        "img=mpimg.imread('./Train/Images/train_1.png')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()\n",
        "imshow(np.pad((x['inst_map']>=1).astype(int),12), cmap='Purples')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#grey\n",
        "class NucleiDataset(Dataset):\n",
        "    def __init__(self, image_path, mask_path, crop_size = 256, k=700, transform=None, draw=False, ls=64, us=8):\n",
        "        self.images = []\n",
        "        self.masks = []\n",
        "        self.image_types = []\n",
        "        images = []\n",
        "        masks = []\n",
        "        img_ls = [image_path+i for i in sorted(os.listdir(image_path))]\n",
        "\n",
        "        mask_ls = [mask_path+i for i in sorted(os.listdir(mask_path))]\n",
        "        self.transform = transform\n",
        "        for img_name, mask_name in zip (img_ls, mask_ls):\n",
        "          img = Image.open(img_name).convert('RGB')\n",
        "          img.load()\n",
        "          mask = np.pad((loadmat(mask_name)['inst_map']>=1).astype(int),12)\n",
        "          #7 types\n",
        "          if self.transform:\n",
        "              img = self.transform(img)\n",
        "          images.append(img)\n",
        "          masks.append(mask)\n",
        "        l = len(images)\n",
        "\n",
        "        for _ in range(ls):\n",
        "          k1 = random.randint(0, l-1)\n",
        "          image = images[k1]\n",
        "          mask = masks[k1]\n",
        "          _, h, w = image.shape\n",
        "          x = np.random.randint(0, w - crop_size -1)\n",
        "          y = np.random.randint(k, h - crop_size -1)\n",
        "          if draw:\n",
        "              draw()\n",
        "          # Обрезка изображения\n",
        "          self.images.append(image[:, y:y+crop_size, x:x+crop_size])\n",
        "\n",
        "          # Обрезка маски\n",
        "          self.masks.append(mask[y:y+crop_size, x:x+crop_size])\n",
        "          self.image_types.append('labeled')\n",
        "          #print(img.shape, mask.shape)\n",
        "        for _ in range(us):\n",
        "          k1 = random.randint(0, l-1)\n",
        "          image = images[k1]\n",
        "          x = np.random.randint(0, w - crop_size - 1)\n",
        "          y = np.random.randint(0, k - crop_size - 1)\n",
        "          # Обрезка изображения\n",
        "          self.images.append(image[:, y:y+crop_size, x:x+crop_size])\n",
        "          self.masks.append(mask[y:y+crop_size, x:x+crop_size])\n",
        "          self.image_types.append('unlabeled')\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.images[idx]\n",
        "        mask = self.masks[idx]\n",
        "        image_type = self.image_types[idx]\n",
        "        return img, mask, image_type#mask[np.newaxis, ...]\n",
        "\n",
        "\n",
        "trans = transforms.Compose([\n",
        "    transforms.Pad(12),    # given image is 1000x1000, pad it to make it 1024x1024\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # imagenet normalization\n",
        "])\n",
        "\n",
        "train_trans = transforms.Compose([\n",
        "    transforms.Pad(12),    # given image is 1000x1000, pad it to make it 1024x1024\n",
        "    transforms.RandomAdjustSharpness(sharpness_factor=2),\n",
        "    transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
        "    transforms.RandomPerspective(distortion_scale=0.6, p=1.0),\n",
        "    transforms.RandomRotation(degrees=(0, 180)),\n",
        "    transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # imagenet normalization\n",
        "])\n",
        "\n",
        "label_path = \"./Train/Labels/\"\n",
        "img_path = \"./Train/Images/\"\n",
        "\n",
        "batch_size = 72  #my gpu is 8gb, using batchsize of 2 already insufficient memory, so i use batch size 1\n",
        "labeled_size = 8\n",
        "unlabaled_size = batch_size - labeled_size\n",
        "train_set = NucleiDataset(img_path, label_path, transform=trans, ls=labeled_size, us=unlabaled_size)\n",
        "\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=False, num_workers=1, drop_last=True)"
      ],
      "metadata": {
        "id": "V3gN3TFH83T3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reverse_transform(inp, mask):\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    inp = (inp * 255).astype(np.uint8)\n",
        "    print(inp.shape, mask.shape)\n",
        "    inp[mask > 0] = (0, 255, 255)\n",
        "\n",
        "    return inp\n",
        "\n",
        "\n",
        "inputs, masks, image_type = next(iter(train_loader))\n",
        "\n",
        "print(inputs.shape, masks.shape)  #shapes of our inputs to the model and loss function\n",
        "\n",
        "plt.imshow(reverse_transform(inputs[0], masks[0]))\n",
        "plt.show()\n",
        "imshow(masks[0],cmap='gray')"
      ],
      "metadata": {
        "id": "s54xFSMivv4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################\n",
        "# Model Architecture #\n",
        "######################\n",
        "\n",
        "def convrelu(in_channels, out_channels, kernel, padding):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
        "        nn.ReLU(inplace=True),\n",
        "    )\n",
        "\n",
        "\n",
        "class ResNetUNet(nn.Module):\n",
        "    def __init__(self, n_class):\n",
        "        super().__init__()\n",
        "\n",
        "        self.base_model = models.resnet18(pretrained=True)\n",
        "        self.base_layers = list(self.base_model.children())\n",
        "\n",
        "        self.layer0 = nn.Sequential(*self.base_layers[:3]) # size=(N, 64, x.H/2, x.W/2)\n",
        "        self.layer0_1x1 = convrelu(64, 64, 1, 0)\n",
        "        self.layer1 = nn.Sequential(*self.base_layers[3:5]) # size=(N, 64, x.H/4, x.W/4)\n",
        "        self.layer1_1x1 = convrelu(64, 64, 1, 0)\n",
        "        self.layer2 = self.base_layers[5]  # size=(N, 128, x.H/8, x.W/8)\n",
        "        self.layer2_1x1 = convrelu(128, 128, 1, 0)\n",
        "        self.layer3 = self.base_layers[6]  # size=(N, 256, x.H/16, x.W/16)\n",
        "        self.layer3_1x1 = convrelu(256, 256, 1, 0)\n",
        "        self.layer4 = self.base_layers[7]  # size=(N, 512, x.H/32, x.W/32)\n",
        "        self.layer4_1x1 = convrelu(512, 512, 1, 0)\n",
        "\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "        self.conv_up3 = convrelu(256 + 512, 512, 3, 1)\n",
        "        self.conv_up2 = convrelu(128 + 512, 256, 3, 1)\n",
        "        self.conv_up1 = convrelu(64 + 256, 256, 3, 1)\n",
        "        self.conv_up0 = convrelu(64 + 256, 128, 3, 1)\n",
        "\n",
        "        self.conv_original_size0 = convrelu(3, 64, 3, 1)\n",
        "        self.conv_original_size1 = convrelu(64, 64, 3, 1)\n",
        "        self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n",
        "\n",
        "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x_original = self.conv_original_size0(input)\n",
        "        x_original = self.conv_original_size1(x_original)\n",
        "\n",
        "        layer0 = self.layer0(input)\n",
        "        layer1 = self.layer1(layer0)\n",
        "        layer2 = self.layer2(layer1)\n",
        "        layer3 = self.layer3(layer2)\n",
        "        layer4 = self.layer4(layer3)\n",
        "\n",
        "        layer4 = self.layer4_1x1(layer4)\n",
        "        x = self.upsample(layer4)\n",
        "\n",
        "        layer3 = self.layer3_1x1(layer3)\n",
        "        x = torch.cat([x, layer3], dim=1)\n",
        "        x = self.conv_up3(x)\n",
        "\n",
        "        x = self.upsample(x)\n",
        "        layer2 = self.layer2_1x1(layer2)\n",
        "        x = torch.cat([x, layer2], dim=1)\n",
        "        x = self.conv_up2(x)\n",
        "\n",
        "        x = self.upsample(x)\n",
        "        layer1 = self.layer1_1x1(layer1)\n",
        "        x = torch.cat([x, layer1], dim=1)\n",
        "        x = self.conv_up1(x)\n",
        "\n",
        "        x = self.upsample(x)\n",
        "        layer0 = self.layer0_1x1(layer0)\n",
        "        x = torch.cat([x, layer0], dim=1)\n",
        "        x = self.conv_up0(x)\n",
        "\n",
        "        x = self.upsample(x)\n",
        "        x = torch.cat([x, x_original], dim=1)\n",
        "        x = self.conv_original_size2(x)\n",
        "\n",
        "        out = self.conv_last(x)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "9miWp-LU3SzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHZ6tgzFk7dw"
      },
      "outputs": [],
      "source": [
        "###################################################################\n",
        "# Loss function that combines Binary Cross Entropy with Dice loss #\n",
        "###################################################################\n",
        "\n",
        "# Model output is (N, 1, 1024,1024), where N = batch size, Thus you will see that i squeeze the 2nd dimension\n",
        "\n",
        "def weighted_loss(pred, targ, bce_weight=0.5, smooth=1., binary=True):\n",
        "\n",
        "    if binary:\n",
        "      bce = F.binary_cross_entropy_with_logits(pred.squeeze(dim=1), targ)\n",
        "    else:\n",
        "      bce = F.cross_entropy(pred, targ)\n",
        "    pred = torch.sigmoid(pred)\n",
        "\n",
        "    pred = pred.contiguous().squeeze(dim=1)\n",
        "    targ = targ.contiguous()\n",
        "\n",
        "    intersection = (pred * targ).sum(dim=1).sum(dim=1)\n",
        "    dice = (1 - ((2. * intersection + smooth) / (pred.sum(dim=1).sum(dim=1) + targ.sum(dim=1).sum(dim=1) + smooth)))\n",
        "    loss = bce * bce_weight + dice.mean() * (1 - bce_weight)\n",
        "    #intersection = (pred * targ).sum(dim=1).sum(dim=1)\n",
        "    #dice = (1 - ((2. * intersection + smooth) / (pred.sum(dim=1).sum(dim=1) + targ.sum(dim=1).sum(dim=1) + smooth)))\n",
        "    return loss, dice, bce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FlIt-IKk9j-"
      },
      "outputs": [],
      "source": [
        "def update_ema_variables(alpha, global_step):\n",
        "    # Use the true average until the exponential average is more correct\n",
        "    alpha = min(1 - 1 / (global_step + 1), alpha)\n",
        "    for ema_param, param in zip(ema_model.parameters(), model.parameters()):\n",
        "        ema_param.data.mul_(alpha).add_(1 - alpha, param.data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOqWK20Ek_9h"
      },
      "outputs": [],
      "source": [
        "def sigmoid_rampup(current, rampup_length):\n",
        "  if rampup_length == 0:\n",
        "      return 1.0\n",
        "  else:\n",
        "      current = np.clip(current, 0.0, rampup_length)\n",
        "      phase = 1.0 - current / rampup_length\n",
        "      return float(np.exp(-5.0 * phase * phase))\n",
        "\n",
        "def get_current_consistency_weight(epoch):\n",
        "    # Consistency ramp-up from https://arxiv.org/abs/1610.02242\n",
        "    consistency = 0.1\n",
        "    consistency_rampup = 200.0\n",
        "    return consistency * sigmoid_rampup(epoch, consistency_rampup)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJuPfKYglCFV"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def metrics_curve(loss_ls, dice_ls, bce_ls):\n",
        "\n",
        "\n",
        "\n",
        "        plt.plot(loss_ls)\n",
        "\n",
        "        print(\"loss curve\")\n",
        "        fig.savefig(\"curr_loss.png\", dpi=fig.dpi)\n",
        "        plt.show()\n",
        "        plt.clf()\n",
        "\n",
        "        print(\"dice loss curve\")\n",
        "        plt.plot(dice_ls)\n",
        "        plt.show()\n",
        "        plt.clf()\n",
        "\n",
        "        print(\"cross entropy loss\")\n",
        "        plt.plot(bce_ls)\n",
        "        plt.show()\n",
        "        plt.clf()\n",
        "\n",
        "def log_losses(supervised_loss, dice, bce, consistency_loss, loss):\n",
        "        print(\"epoch supervised loss:\", supervised_loss)\n",
        "        print(\"epoch dice:\", dice.mean())\n",
        "        print(\"epoch bce:\", bce)\n",
        "        print(\"unsupervised loss\", consistency_loss)\n",
        "        print(\"loss\", loss)\n",
        "\n",
        "\n",
        "def draw_image_and_mask(inputs, outputs, masks):\n",
        "        print(\"\\n\",\"Input Image\", inputs.to('cpu').detach()[0].shape, outputs.to('cpu').detach()[0].shape)\n",
        "        plt.imshow(reverse_transform(inputs.to('cpu').detach()[0], masks.to('cpu').detach()[0]))\n",
        "        plt.show()\n",
        "        print(\"Predicted Mask Sigmoid\")\n",
        "        plt.imshow(outputs.to('cpu').detach().numpy()[0][0])\n",
        "        plt.show()\n",
        "        print(\"True mask\")\n",
        "        plt.imshow(masks.to('cpu').detach()[0]) #, cmap='gray'\n",
        "        plt.show()\n",
        "\n",
        "def draw():\n",
        "\n",
        "    overlay = np.array(image.cpu().detach().numpy(), dtype = np.uint8).transpose(1, 2, 0)\n",
        "\n",
        "    np_image = overlay\n",
        "    overlay = cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "\n",
        "    cv2.rectangle(overlay, (0, 0), (w, h-k), (0, 200, 0), -1)\n",
        "    alpha = 0.3  # Transparency factor.\n",
        "\n",
        "    # Following line overlays transparent rectangle\n",
        "    # over the image\n",
        "    image_new = cv2.addWeighted(overlay, alpha, np_image, 1 - alpha, 0)\n",
        "    cv2_imshow(image_new)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "    overlay = image_new.copy()\n",
        "    cv2.rectangle(overlay, (0, h-k), (w, h), (100, 0, 50), -1)\n",
        "\n",
        "    alpha = 0.3  # Transparency factor.\n",
        "    # Following line overlays transparent rectangle\n",
        "    # over the image\n",
        "    image_new = cv2.addWeighted(overlay, alpha, image_new, 1 - alpha, 0)\n",
        "    cv2_imshow(image_new)\n",
        "    cv2.waitKey(0)"
      ],
      "metadata": {
        "id": "cUCCB9SH09IS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mix_unlabeled(unlabeled_bs, unlabeled_volume_batch_0, unlabeled_volume_batch_1):\n",
        "      ict_alpha = 0.21\n",
        "      ict_mix_factors = np.random.beta(\n",
        "          ict_alpha, ict_alpha, size=((unlabeled_bs // 2, 1, 1, 1)))\n",
        "      ict_mix_factors = torch.tensor(\n",
        "          ict_mix_factors, dtype=torch.float).cuda()\n",
        "\n",
        "      batch_ux_mixed = unlabeled_volume_batch_0 * \\\n",
        "          (1.0 - ict_mix_factors) + \\\n",
        "          unlabeled_volume_batch_1 * ict_mix_factors\n",
        "\n",
        "      return batch_ux_mixed, ict_mix_factors"
      ],
      "metadata": {
        "id": "iP_VSDx_Evuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npSSTNS5klYH"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "import random\n",
        "import torchvision.transforms as T\n",
        "from google.colab.patches import cv2_imshow\n",
        "pil_transform = T.ToPILImage()\n",
        "def train_model(optimizer, scheduler, num_epochs=25):\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = 1e10\n",
        "\n",
        "    ema_decay = 0.99\n",
        "    labeled_bs = 8\n",
        "    loss_ls = []\n",
        "    dice_ls = []\n",
        "    bce_ls = []\n",
        "    iter_num = 0\n",
        "    unlabeled_bs = 64\n",
        "    crop_size = 256\n",
        "    draw = False\n",
        "\n",
        "    k = 700\n",
        "\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "        since = time.time()\n",
        "        supervised_loss = 0\n",
        "\n",
        "\n",
        "        for inputs, masks, image_type in train_loader:\n",
        "            print(inputs.shape, masks.shape, inputs[0].shape, masks[0].shape)\n",
        "            labeled_images = []\n",
        "            labeled_masks = []\n",
        "            unlabeled_images = []\n",
        "            model.train()\n",
        "\n",
        "            labeled_images = inputs[:8].to(device)\n",
        "            unlabeled_images = inputs[8:].to(device)\n",
        "            labeled_masks = masks[:8].to(device).float()\n",
        "\n",
        "            #ICT mix factors\n",
        "            print(\"shapws\", labeled_images.shape, unlabeled_images.shape)\n",
        "\n",
        "            unlabeled_volume_batch_0 = unlabeled_images[0: unlabeled_bs // 2, ...]\n",
        "            unlabeled_volume_batch_1 = unlabeled_images[unlabeled_bs // 2:, ...]\n",
        "\n",
        "\n",
        "            #Mix images\n",
        "            batch_ux_mixed, ict_mix_factors = mix_unlabeled(unlabeled_bs, unlabeled_volume_batch_0, unlabeled_volume_batch_1)\n",
        "\n",
        "            input_volume_batch = torch.cat(\n",
        "                [labeled_images, batch_ux_mixed], dim=0)\n",
        "            outputs = model(input_volume_batch)\n",
        "\n",
        "            with torch.no_grad():\n",
        "              ema_output_ux0 = ema_model(unlabeled_volume_batch_0)\n",
        "              ema_output_ux1 = ema_model(unlabeled_volume_batch_1)\n",
        "              batch_pred_mixed = ema_output_ux0 * \\\n",
        "                  (1.0 - ict_mix_factors) + ema_output_ux1 * ict_mix_factors\n",
        "            #print(outputs[:labeled_bs].shape, labeled_masks[:labeled_bs].shape)\n",
        "            supervised_loss, dice, bce = weighted_loss(outputs[:labeled_bs], labeled_masks[:labeled_bs], bce_weight=0.5)\n",
        "            iter_num += 1\n",
        "\n",
        "            consistency_weight = get_current_consistency_weight(iter_num // 150)\n",
        "            consistency_loss = torch.mean(\n",
        "                (outputs[labeled_bs:] - batch_pred_mixed) ** 2)\n",
        "            loss = supervised_loss + consistency_weight * consistency_loss\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            update_ema_variables(ema_decay, iter_num)\n",
        "\n",
        "            dice_ls.append(dice.mean().item())\n",
        "            loss_ls.append(loss.item())\n",
        "            bce_ls.append(bce.item())\n",
        "\n",
        "            log_losses(supervised_loss, dice, bce, consistency_loss, loss)\n",
        "\n",
        "            metrics_curve(loss_ls, dice_ls, bce_ls)\n",
        "\n",
        "\n",
        "        if (epoch+1)%4==0:\n",
        "            draw_image_and_mask(inputs, outputs, masks)\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60),\"\\n\")\n",
        "\n",
        "\n",
        "    return loss_ls, model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(ema=False):\n",
        "  # Network definition\n",
        "  model = ResNetUNet(1).to(device)\n",
        "  if ema:\n",
        "    for param in model.parameters():\n",
        "        param.detach_()\n",
        "  return model\n",
        "\n",
        "\n",
        "model = create_model()\n",
        "#model.load_state_dict(torch.load('semi-supervised.pt', map_location=torch.device('cpu')))\n",
        "ema_model = create_model(ema=True)\n",
        "\n",
        "\n",
        "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
        "\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=30, gamma=0.1)\n",
        "\n",
        "loss_ls = train_model(optimizer_ft, exp_lr_scheduler, num_epochs=500)"
      ],
      "metadata": {
        "id": "GMbxXtHFC2Bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjPafqqLX_8V"
      },
      "outputs": [],
      "source": [
        "def create_model(ema=False):\n",
        "  # Network definition\n",
        "  model = ResNetUNet(1).to(device)\n",
        "  if ema:\n",
        "    for param in model.parameters():\n",
        "        param.detach_()\n",
        "  return model\n",
        "\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "ema_model = create_model(ema=True)\n",
        "\n",
        "\n",
        "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
        "\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=30, gamma=0.1)\n",
        "\n",
        "loss_ls = train_model(optimizer_ft, exp_lr_scheduler, num_epochs=60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uC6Li-HxbAGr"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'semi-supervised-1classes.pt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del train_loader"
      ],
      "metadata": {
        "id": "F_BAYZFzIm62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_FVwXHUlLJA"
      },
      "outputs": [],
      "source": [
        "#######################\n",
        "# Test Set Dataloader #\n",
        "#######################\n",
        "\n",
        "label_path = \"./Test/Labels/\"\n",
        "img_path = \"./Test/Images/\"\n",
        "\n",
        "test_set = NucleiDataset(img_path,label_path, transform = trans)\n",
        "\n",
        "batch_size = 1\n",
        "\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqjfpsSS6sSd"
      },
      "outputs": [],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q62d55lmlOIi"
      },
      "outputs": [],
      "source": [
        "#inputs, masks = next(iter(test_loader))\n",
        "#from torchvision.utils import draw_segmentation_masks\n",
        "dices = []\n",
        "losses = []\n",
        "smooth=1.\n",
        "crop_size = 256\n",
        "for inputs, masks, t in test_loader:\n",
        "  print(\"Input Image\")\n",
        "\n",
        "  plt.show()\n",
        "  outputs = model(inputs.to(device))\n",
        "\n",
        "  outp = torch.sigmoid(outputs).to('cpu')\n",
        "\n",
        "\n",
        "  outp = outp.contiguous().squeeze(dim=1)\n",
        "\n",
        "  targ = masks.contiguous().to('cpu')\n",
        "\n",
        "  intersection = (outp * targ).sum(dim=1).sum(dim=1)\n",
        "\n",
        "  dice = (1 - ((2. * intersection + smooth) / (outp.sum(dim=1).sum(dim=1) + targ.sum(dim=1).sum(dim=1) + smooth)))\n",
        "\n",
        "  print(\"dice\", dice.mean())\n",
        "\n",
        "\n",
        "  pred = outputs.to('cpu').detach().numpy()[0][0]\n",
        "\n",
        "  #draw_segmentation_masks(inputs, masks)\n",
        "  #draw_segmentation_masks(inputs, masks)\n",
        "\n",
        "  #preds = torch.argmax(softmax(outputs),axis=1).to('cpu')\n",
        "\n",
        "\n",
        "  print(\"Predicted Mask Sigmoid\")\n",
        "  plt.imshow(pred)\n",
        "\n",
        "  plt.show()\n",
        "  threshold=0.95     # vary the threshold\n",
        "  pred[pred >= threshold] = 1\n",
        "  pred[pred < threshold] = 0\n",
        "\n",
        "  #pred[pred_1 < threshold  pred_2 < threshold  pred_3 < threshold] = 0\n",
        "\n",
        "  print(\"Predicted Mask Binary\")\n",
        "  plt.imshow(pred.T)\n",
        "  plt.show()\n",
        "  print(\"Actual Mask\")\n",
        "  plt.imshow(masks[0].T)\n",
        "  plt.show()\n",
        "  dices.append(dice.mean().item())\n",
        "  print(dices)\n",
        "  #dices.append(dice)\n",
        "  #losses.append(loss)pred\n",
        "\n",
        "  del outputs\n",
        "  del outp\n",
        "  del targ\n",
        "  del pred\n",
        "\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "print(\"final dice\", sum(dices) / len(dices))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udkvGmPUlLMf"
      },
      "outputs": [],
      "source": [
        "dice_arr = [0.2202581763267517, 0.3833320736885071, 0.23471367359161377, 0.28936779499053955, 0.2180195450782776, 0.267808735370636, 0.21645820140838623, 0.21842467784881592, 0.23607689142227173, 0.23001813888549805, 0.27057749032974243, 0.24977004528045654, 0.25484317541122437, 0.18952924013137817]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xS1T0Qt2lLOp"
      },
      "outputs": [],
      "source": [
        "sum(dice_arr) / len(dice_arr)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "history_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}